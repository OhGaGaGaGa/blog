# 机器学习与统计学

仅作为学习过程中的一些总结，必有疏漏错误，烦请指正。

相比于统计学的大领域，机器学习更加侧重与对于未知数据的预测，从部分已知数据推断出全部数据，从已有数据生成更多未知数据。

## 有监督学习：回归、判别与分类

**回归**

对于要应用于**连续型**数据的情景，我们可以通过已有数据，拟合出回归模型。常用的回归模型主要为线性回归模型。通过回归模型，我们可以进行回归预测，如在均方误差最小的情形下，使用 $X$ 对 $y$ 的最优预测就是 $\mathbb{E}(y|\mathbf{X})$。不过对于回归的分析的理论价值较高，实际应用中对于对数据的连续预测需求并没有很大。

- 连续型
- 线性回归（回归数据的检验、模型的检验、自变量的选择等）

**判别与分类**

判别（Discrimination）指利用具有类别信息的观测数据（Training Dataset）建立一个分类器（Classifier）或者分类法则（Classification Rule），其可以最大可能地区分事先定义的类。(Separation)

分类（Classification）指给定一组新的未知类别信息的观测数据集，使用分类器或分类法则将其分配到一些已知的类中。(Allocation)

实际应用中，判别与分类常常混在一起。判别更偏向于建立模型，而分类更偏向于使用模型进行预测。

- 离散型
- 距离判别、极大似然判别、Fisher 线性判别、Bayes 判别、感知机、KNN、SVM、Logistic 回归、决策树

- 分类效果的度量

## 无监督学习：聚类、PCA、因子模型

