# CS231n: Convolutional Neural Networks for Visual Recognition - 2017

## 1 课程介绍

Image Classification 图片分类

Object detection 目标检测, Action classification 动作分类, Image captioning 描述图像

变化：算力 Computation 带有标签的数据 Data

## 2 图像分类

### 流程

语义鸿沟 semantic gap: 计算机只能看到 RGB 值，这和人的实际视觉是有差异的

我们的算法应该对以下条件鲁棒：遮挡/光线/姿态/背景混乱/类内差异/...

**train & predict**

```python
def train(images, lables):
    # Machine learning!
    return model

def predict(model, test_images):
    # Use model to predict labels
    return test_labels
```

### 最近邻 & K近邻 判别分析

Nearest Neighbor & K-<u>N</u>earest <u>N</u>eighbor

使用 L1 距离：sum of absolute value differences

```python
import numpy as np
class NearestNeighbor:
    def __init__(self):
        pass
    def train(self, X, y):
        self.Xtr = X # N * D, each row is an example
        self.ytr = y # N * 1
    def predict(self, X):
        num_test = X.shape[0] # X: num_test * D
        Ypred = np.zeros(num_test, dtype = self.ytr.dtype) # y: num_test * 1
        
        for i in xrange(num_test):
            distances = np.sum(np.abs(self.Xtr - X[i, :]), axis = 1)
            min_index = np.argmin(distance)
            Ypred[i] = self.ytr[min_index]
    	
        return Ypred
```

时间复杂度：train O(1), predict O(n)。

实际使用时，预测上要花尽可能少的时间，但是对训练的时间反而没有太多要求。

最近邻的缺陷：干扰点，可能在划分后有太过波动的边界。

所以引入最近邻，采用多数投票的方式确定分类。

![image-20220120143612701](https://gitee.com/ohg/typora_image/raw/master/imgs/2022/01/202201201436927.png)

不用于图像识别：可以构造出完全不同的照片相对于原照片得到的距离是相同的; Curse of dimensionality

L1 distance (Manhattan distance)：45°倾斜的正方形；受到所选的坐标轴影响，如果旋转坐标轴可能会影响L1距离的值，坐标轴往往有具体的含义
$$
d_1(I_1, I_2) = \sum_p{|I^p_1-I^p_2|}
$$
L2 distance (Euclidean distance)：圆形；不受坐标轴的选取的影响，当坐标轴没有具体含义时更实用
$$
d_2(I_1, I_2) = \sqrt{\sum_p{(I^p_1-I^p_2)^2}}
$$
http://vision.stanford.edu/teaching/cs231n-demos/knn/

![image-20220120145943128](https://gitee.com/ohg/typora_image/raw/master/imgs/2022/01/202201201459410.png)

L1 距离是与坐标轴相关的，而 L2 距离和坐标轴不相关。所以如果坐标轴是有一些特殊含义的，比如特征向量之类，那可以用 L1；如果坐标轴是随便找的，那就 L2。

1-Nearest Neighbor Classifier 无法辨别噪声

K-Nearest Neighbor Classifier 最近的K个点

Hyperparameters 超参数：比如刚刚的距离选择、K的选择 choices about the algorithm that **we set rather than learn**. 

会产生维度灾难：维度增加时，要想得到相同的精度，所需要的数据是指数级增长的。

#### Assignment - KNN

在此记录一些完成作业过程中，在样例中发现的较好用法，以及 `numpy` 的基本使用。

##### numpy

**`arr.shape`**：一个 `tuple`，返回各个维度的大小。

**`numpy`中`np.flatnonzero()`的用法**

返回向量化矩阵后，满足括号内条件的元素下标。

```python
>>> x = np.array([1,2,3,0,2])
>>> np.flatnonzero(x)
array([0, 1, 2, 4])
>>> x = np.array([[1,2,3], [0,8,2]])
>>> np.flatnonzero(x == 2)
array([1, 5])
```

**`numpy`中`np.random.choice()`的用法**

从一维数组（离散总体）中随机抽样：`numpy.random.choice(a, size=None, replace=True, p=None)`。

- `a`: 抽样总体，可以是一维数组或者是一个数字（表示range）
- `size`: 抽样大小，默认为1。
- `replace`: `True`表示可以取相同数字，`False`表示不可以取相同数字
- 数组`p`: 表示取数组`a`中每个元素的概率，默认为选取每个元素的概率相同。

```python
>>> np.random.choice(5) # 从[0, 5)中随机输出一个随机数，相当于np.random.randint(0, 5)
3
>>> x = tuple((1, 2, 3, 5))
>>> np.random.choice(x, 2, replace=False)
array([5, 2])
```

**`numpy`中`np.reshape()`的用法**

`np.reshape(arr, newshape, order='C')`，`arr.reshape(newshape, order='C')`

- `newshape`: `int`或tuple的整数：如果是整数D，则结果将是该长度的1-D数组；某一形状维度可以是-1，此时从其余维度推断该值。
- `order`: 索引顺序，可选{'C'，'F'，'A'}。使用此索引顺序读取`arr`的元素，并使用此索引顺序将元素放置到重新形成的数组中。`'C'`意味着使用顺序读取/写入元素，最后一个轴索引变化最快，回到第一个轴索引变化最慢。`'F'`意味着使用Fortran样索引顺序读取/写入元素，第一个索引变化最快，最后一个索引变化最慢。

注意，`reshape`改变数组时，是引用改变的，改变`reshape`后的值也会改变原数组的值。

```python
arr.reshape(m, -1) #改变维度为m行、d列 (-1表示列数自动计算，d= a*b /m)
arr.reshape(-1, m) #改变维度为d行、m列 (-1表示行数自动计算，d= a*b /m)

>>> x = np.array((1, 2, 3, 5))
>>> y = np.reshape(x, (2,2))
>>> y
array([[1, 2],
       [3, 5]])
>>> y[1][1] = 6
>>> x
array([1, 2, 3, 6])
>>> y = x.reshape((1, -1))
>>> y
array([[1, 2, 3, 6]])
>>> x = y.reshape(1)
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
ValueError: cannot reshape array of size 4 into shape (1,1)
>>> x = y.reshape((4))
>>> x
array([1, 2, 3, 6])
>>> x = y.reshape((-1,4))
>>> x
array([[1, 2, 3, 6]])
>>> x = y.reshape((4,-1))
>>> x
array([[1],
       [2],
       [3],
       [6]])
```

**`numpy`中`np.sum()`的用法**

注意第二个参数，`axis`，代表对第几维求和。

```python
>>> X = np.array([[2,3,4], [7,8,9]])
>>> Y = np.array([[11, 12, 13], [5, 6, 7]])
>>> np.sum(X[0] - Y[0])
-27
>>> np.sum(X - Y, axis = 1)
array([-27,   6])
```

**`numpy`中`np.multiply()`的用法**

如果一个矩阵为数，则就是数乘。

默认：矩阵的 Hadamard 积，对应项相乘。

矩阵乘法：`np.dot()`。如果向量和矩阵相乘，会把向量转为矩阵。如果其中一个乘数为数，则视为数乘。

**`numpy`中`np.bincount()`的用法**

计算一维非负数组中每个元素出现了多少次 `bincount(x, weights=None, minlength=0)`

`minlength`：输出数组中的最短长度。

```python
>>> np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))
array([1, 3, 1, 1, 0, 0, 0, 1])
>>> np.bincount(np.arange(5))
array([1, 1, 1, 1, 1])
>>> w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # weights
>>> x = np.array([0, 1, 1, 2, 2, 2])
>>> np.bincount(x, weights=w)
array([ 0.3,  0.7,  1.1])
```

**`numpy` 中的 `np.argsort()` `np.argmax()` `np.argmin()`**

排序/取最值后，返回下标数组。

##### 利用矩阵乘法计算欧式距离

$$
\begin{aligned}
dist_{i,j} &= \sqrt{\sum_{k = 1}^D(test_{i,k} - train^T_{k.j})^2}\\
&= \sqrt{\sum_{k = 1}^D test_{i,k}^2 - 2test_{i,k}train^T_{k.j} + {train^T_{k.j}}^2}\\
\end{aligned}
$$

```python
dists = np.repeat(np.sum(np.square(X), axis = 1), num_train).reshape(num_test, num_train)
dists += np.repeat(np.sum(np.square(self.X_train.T), axis = 0), num_test).reshape(num_train, num_test).T
dists += -2 * np.dot(X, self.X_train.T)
dists = np.sqrt(dists)
```

### Data

Train Data & Test Data: 我们不能选择在 Train Data 或者是 Test Data 中表现最好的超参数，因为这样会让我们的训练具有依赖性。

Train Data & Valuation Data & Test Data: 在交稿前一周再去接触 Test Data 进行测试。

我们可以看到 Train Data 中的 Label，但是不能看到 Valuation Data 中的 Label，只是验证它是不是正确的。

Cross Valuation 交叉验证：小数据集中常用，将 Test Data 分离出来之后，剩下的数据分组，每组轮流当 Valuation Data。

要尽量使得分组是完全随机的，不要有时间差，也不要有拍摄者/数据来源的偏差。

Test Data 的目的，是看这个模型在未知数据上的效果如何，所以我们不能把这个未知数据给变成已知，如果这样那 Test Data 就不再是未知的数据，没办法测试这个模型在位置数据上面的效果了。

假定多个不同的超参数后，通过 Train Data 去训练，然后再去用 Validation Data 验证这些超参数的效果，找到最好的那些超参数。最后这些参数在 Test Data 里的测试效果就是这个超参数以及这个模型对于未知数据的效果。

### Linear Classification 线性分类

在预测时，我们不使用实际的训练数据预测，而是通过一定的算法计算出这些数据所对应的 Weight，再将 Weight 作为参数传递。

分类器 $f$ 是一个映射：
$$
f:x, w\to scores_{G_i}
$$
$x$ 是要预测的数据，$w$ 是训练出的参数，$scores_{G_i}$ 是把 $x$ 分类为 $G_i$ 的得分。若 $f$ 的形式是线性的，即 $f(x, w) = wx$，则称之为 线性分类器 Linear Classifier。这时，$f(x,w)$ 是一个 $GroupCnt\times 1$ 的向量，$x$ 是 $n\times 1$ 向量，而训练出的 $w$ 是 $GroupCnt\times n$ 的矩阵。实际应用中，我们把 $p\times p$ 个像素的图片的 3 个通道拉伸成 $(p\times p\times3)\times 1$ 的向量作为 $x$。

如果有一些先验知识，比如已经知道猫的数量远多于狗，那可以在 $wx$ 后面加一个 Bias 向量 $b$，得到 $f(x,w) = wx + b$，通过这样得到的 $f(x,w)$ 的 score 再去判定分类。

每一个类别都能对应一幅 image，这个 image 可以用一个行向量来表示；行向量组合起来便成为权值矩阵 $w$。这个权值矩阵的每一行是有意义的，把它使用 RGB 画出之后，是可以对应一副图片的。

如果把所有的图片都看作是分布在一个高维空间中，那么 Linear Classifier 可以看作是一条线，把某一类的图片与其他种类的图片区分开。

无法解决的问题：

1. 奇偶分类是线性分类器以及传统分类器所无法解决掉的，因为必定不可能存在一个线性的结构使得可以把他们分离开。
2. 无法解决不连续的多模态数据：马可以向左看，也可以向右看；但是并不能有一条线性边界把他们划分成同一类，且不包含其他数据。它会选取所有变体的平均值；使用同一个模板，来识别某件事物的所有种类；某个类别对应的权值矩阵中的那一行所画出的那个 image 可能出现两只头的马。

## 3 Loss Function and Optimization

How can we tell whether this W is good or bad? 正确分类，且要让正确的分类对应的 Score 尽可能的高。

We need some way (**Loss Function**) to <u>quantify</u> the badness of any particular W. 

We need to find and come up with an efficient procedure for searching through <u>the space of all possible Ws</u> and actually come up with what is the correct value of <u>W that is the least bad</u>. 

我们有一个 training dataset $ \{(x_i, y_i)\} $，$x_i$ 是图片，$y_i$ 是标签。预测函数 $f(x_i, {\rm W})$ 可以得到图片 $x_i$ 在 $\rm W$ 下，对10个分类得到的值；损失函数 $L_i(y^{predict}_i = f(x_i, {\rm W}), y_i)$ 得到预测值与实际值相比的评分，总的损失函数 $L=\frac{1}{N}\sum L_i(f(x_i, {\rm W}), y_i)$。这里 $i$ 对应的是样本，不是对样本预测时的各种分类。

### Multi-Class SVM Loss

多分类支持向量机，是二元支持向量机模型的推广。

处理多分类问题的多分类 SVM 的损失函数：
$$
\begin{align}
L_i & = \sum_{j\neq y_i}\begin{cases} 
		0 &, {\rm if}\ s_{y_i} \ge s_j+1\\
		s_j-s_{y_i}+1 &, {\rm otherwise}\\ 
		\end{cases} \\
& = \sum_{j\neq y_i} \max(0, s_j-s_{y_i}+1) \\
\end{align}
$$

But what this is saying is that the loss $L_i$ for any individual example, the way we'll compute it is we're going to perform a sum over all of the categories $y$ except for the true category $y_i$. So, we're going to sum over all the incorrect categories, and the we're going to compare the score of the correct category, and the score of the incorrect category. And now if the score for the correct category is greater than the score of the incorrect category , greater than the incorrect score by some safety margin, that we set to 1, if that is the case that means that **the score of true category is much larger than any of the false categories**, **then the loss is zero**. And we'll sum this up over all of the incorrect categories for our images, and this will give us our final loss for this one example in the data set. And again, we'll take the average of this loss over the whole training data set. 

如果分类到 $j$ 的分数比分类到 $y_i$ 的分数高的太多，或者说分类到 $j$ 的分数和分类到 $y_i$ 的分数是很接近的（在阈值内），那我们都认为这是存在 Loss 的。当对正确分类$y_i$的预测分数明显高于其他分类，那我们才会满意。

$y_i$ 表示第 $i$ 条图片数据对应的 Class，表示应该分到第 $y_i$ 类。通过比较 Score 得到的 Score 最高的分类是 $\hat{y_i}$，表示对 $i$ 分类的预测。

这是一个**合页损失函数**/铰链损失函数（Hinge Loss Function）

如果用x轴表示对这个样本计算出来的分数，用y轴表示这个分数所代表的损失。那这个函数时单调线性下降的，但当y值下降到0时，便不再下降；且x再增加，y也恒为0。

这里的阈值可以任意选择，因为参数矩阵 $w$ 是训练出来的，我们可以通过一定的 Scale 来使得训练出相同效果的模型。

第一次迭代时，我们一般会取 $w$ 的初值为一些绝对值较小的随机数，这样得到的 Score 一开始都很小，且类似均匀分布。如果一共有 $C$ 张图片，那么得到的结果应该是 $\Delta\times (C-1)$（在上面的案例中 $\Delta = 1$ ），因为 $s_i$ 应该都非常接近，所以 $s_j-s_{y_i}\approx 0$。如果第一次迭代时的结果不对，那很可能是代码错了。

我们使$j\neq y_i$的原因是为了避免给$L_i$加上一个多余的$\Delta$。如果加了，会造成当$\Delta$取不同的值的时候，得到的结果不一样，且不为0，我们想让他是0。

我们并不在意$L_i$的具体值，我们只在意它是不是0。所以我们可以取平均值，或者是乘上一个什么系数。

选择平方的损失函数，即 $\max(0, (s_j-s_{y_i}+1)^2)$，可能更关注减少单个分类的损失，因为如果某个损失特别大那就会导致 Loss Function 这个整体特别大；而选择线性的损失函数，可能更关注减小整体的损失。

```python
def L_i_vectorized(x, y, W):
    scores = W.dot(x)
    margins = np.maximum(0, scores - scores[y] + 1)
    margins[y] = 0
    loss_i = np.sum(margins)
    return loss_i
```

### 正则化 Regularization

解决**过拟合**的问题
$$
L(W) = \frac{1}{N}\sum_{i=1}^NL_i(f(x_i, W), y_i) + \lambda R(W)
$$

鼓励模型选择更简单的 W，所以增加一项惩罚项，$\lambda$ 是超参数 hyper-parameter。

常用的正则化：

L2 正则化：计算权值矩阵的欧式范数，会均衡各个权值系数，不会有过大的出现，可以利用每个 $x$ 的信息，更为整体化： $R(W) = \sum_k \sum_l W_{k,l}^2$

L1 正则化：鼓励稀疏矩阵，$R(W) = \sum_k \sum_l |W_{k,l}|$

### Multi-Class Logistic Regression - Softmax Loss

如果使用 Softmax Loss，我们可以给线性分类器预测出的 Score 一个特殊的含义。联想 Logistic 回归中的参数的概率含义，这里也有类似的意义。

我们给 Score 一个含义，使其代表未标准化的选择这一类的对数概率 Unnormalized log probabilities：
$$
P(Y = k|X = x_i) = \dfrac{\exp(s_k)}{\sum_j \exp(s_j)}
$$
所以我们可以得到使用 Logistic 回归时，这件图片选择 $i$ 类的 Loss Function $L_i$（这是一个交叉熵损失函数）：
$$
\begin{aligned}
L_i &= -\ln P(Y = y_i|X = x_i)\\
&= -\ln(\dfrac{\exp(s_k)}{\sum_j \exp(s_j)})\\
\end{aligned}
$$
具体过程：对使用线性分类器预测得到的 Scores 求指数，得到 exp(Scores)，再标准化，再取负对数。

如果只有正确的分类的 exp(Score) 是非零的，其他的分类的 exp(Score) 都是 0 ，那么得到的 $L_i = 0$。

第一次迭代时的检验：我们一般会取 $w$ 的初值为一些绝对值较小的随机数，这样得到的 Score 一开始都很小，且类似均匀分布。如果一共有$C$张图片，那么得到的 $L_i$ 结果应该是 $-\ln(1/C) = \ln C$，因为 $s_i\approx 0$ 。如果第一次迭代时的结果不对，那很可能是代码错了。

这里的 $i$ 只取正确的 Class 对应的 Score 计算出的 $L_i$，而 SVM 中使用的是所有其他的 $j\neq i$ 的合页损失之和。最终的损失函数是 $\sum_i L_i / n$。

### 两种 Loss Function 对比

SVM Loss 会在将正确分类和其他分类拉开差距（超过阈值）后，就不再管它了，因为再怎么调整都不会对 $L_i$ 产生影响了。

Softmax Loss 则会不断拉开正确分类的 Score 和不正确分类的 Score 之间的距离，这样才能使得概率尽可能趋近于 1，即 $L_i$ 尽可能趋近于 0。

![image-20220124115259549](https://gitee.com/ohg/typora_image/raw/master/imgs/2022/01/202201241153281.png)

### Optimization

怎样去在已有的 $W$ 的基础上，寻找它的邻域，这样就可以找到新的 $W'$ 并计算 Loss Function 决定是否更新。

沿梯度方向可以使得找到上升最快的路，沿梯度方向的负方向可以找到下降最快的路。

计算梯度时，对每一维都计算近似偏导数：使用定义
$$
\dfrac{\partial{L}}{\partial W_{ij}} = \lim_{h\to 0} \dfrac{L(W_{(ij)}+h)-L(W_{ij})}{h}
$$
$L(W_{(ij)}+h)$ 表示在 $W$ 矩阵的第 $i$ 行第 $j$ 列加上 $h$，之后再计算 Loss Function。实际应用时，不会使用求极限，而是直接给 $h$ 赋一个很小的值，如 0.0001。则梯度即可以用 $\Delta L / h$ 来估计。这样有一个很大的缺陷是，时间复杂度太高。

另一种解析的思路是，首先计算出 $\mathrm{grad}W$ 的表达式，然后直接代入不同的 $W$ 值。

通常使用解析法，但是会使用数值法来进行 Debug。

**朴素的梯度下降**

```python
while True:
    weights_grad = evaluate_gradient(loss_fun, data, weights)
    weights += - step_size * weight_grad
```

每一步的步长 `step_size`：学习率 - **Learning Rate**

**随机梯度下降**

引入 `batch_size`。

每次从样本中抽取 `batch_size` 件样本，只用这一小部分样本去作为 Loss Function 中的样本并由这个小样本 Loss Function 计算出 $W$ 的梯度，然后再梯度下降。

```python
while True:
    data_batch = sample_training_data(data, 256)
    weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
    weights += - step_size * weights_grad
```

可以视作是一种蒙特卡洛估计。

http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/

### 特征转换 Feature Transform

沿着特征向量方向投影，或者是进行一些非线性的映射，类似较为广义的 Fisher 判别

这样能把一些线性分不开的东西，变成线性可分的，并尽可能拉大他们之间的距离。

一些简单的针对图像的特征：

- 光谱直方图，把光谱分割成一个个小区间，统计图片中的像素分布于哪些小区间，然后把这个计数和作为特征。
- 有向梯度直方图：把图片中每 8\*8 个像素作为一组，记录每组中的形状边缘的方向

## 4 反向传播 Backprop

计算图 Computational Graphs

使用链式法则进行递归运算，实现反向传播，最终计算出 $\mathrm{grad} W$。

对于每一个计算图中的中间节点，都有几个输出(local output)和几个输入(local input)，输出可以对输入求偏导(local gradient)。把图中一条线上的所有节点的偏导乘起来，就使用链式法则得到了最终结果。

在计算图中，首先通过初始变量的值算出一个个中间节点的值，我们可以把这些中间节点的输出视为中间变量。而由于 $\dfrac{\mathrm{d}f}{\mathrm{d}x} = \dfrac{\mathrm{d}f}{\mathrm{d}q} \dfrac{\mathrm{d}q}{\mathrm{d}x}$，要想把这个梯度反向传播回去，即已有了 $\dfrac{\mathrm{d}f}{\mathrm{d}q}$，再乘上 Local Gradient 即可。实际应用中，我们总是想要数值解，所以我们需要正向传播去算出 $x$ 的值和 $q$ 的值，然后 $\dfrac{\mathrm{d}f}{\mathrm{d}q}$ 和 $\dfrac{\mathrm{d}q}{\mathrm{d}x}$ 就变成两个数，可以直接进行乘积。

### Example

<img src="https://gitee.com/ohg/typora_image/raw/master/imgs/2022/01/202201241537788.png" alt="image-20220124153702552" style="zoom:80%;" />

要注意，最后面的 $\dfrac{\mathrm{d}f}{\mathrm{d}f} = 1$，这可以作为反向传播的初值。

**加法: Gradient Distributer**

<img src="https://gitee.com/ohg/typora_image/raw/master/imgs/2022/01/202201241545691.png" alt="image-20220124154530852" style="zoom:80%;" />

**乘法: Gradient Switcher**

<img src="https://gitee.com/ohg/typora_image/raw/master/imgs/2022/01/202201241547623.png" alt="image-20220124154712902" style="zoom:80%;" />

**中间节点合并 - Sigmoid Function**
$$
\sigma(x) = \frac{1}{1 + e^{-x}}
$$
可以直接求导，然后把几个中间节点合在一起。
$$
\frac{\mathrm{d}\sigma(x)}{\mathrm{d}x} = \frac{e^{-x}}{(1 + e^{-x})^2} = (\frac{1 + e^{-x} - 1}{1 + e^{-x}})(\frac{1}{1 + e^{-x}}) = (1 - \sigma(x))\sigma(x)
$$
因为可以求出它的 Local Gradient，所以可以稍微整合一下。

**最值: Gradient Router**

<img src="https://gitee.com/ohg/typora_image/raw/master/imgs/2022/01/202201241609658.png" alt="image-20220124160938591" style="zoom:33%;" />

**多个输出**

使用链式法则，将两个输出传过来的梯度相加。
$$
\frac{\mathrm{d}f}{\mathrm{d}x} = \sum_i \frac{\mathrm{d}f}{\mathrm{d}q_i}\frac{\mathrm{d}q_i}{\mathrm{d}x}
$$

### 向量情形

使用 Jacobi 矩阵和矩阵微商替代刚刚的一维导数。

**矩阵微商定义**：设 $X$ 是 $m\times n$ 矩阵，$y = f(X)\in \mathbb{R}$ 是 $X$ 的一个实值函数，则实数 $y$ 对 $X$ 的微商定义为
$$
\frac{\partial y}{\partial X} \xlongequal{\triangle} \begin{bmatrix}
\frac{\partial y}{\partial x_{11}} & \frac{\partial y}{\partial x_{12}} & \cdots & \frac{\partial y}{\partial x_{1n}}\\
\frac{\partial y}{\partial x_{21}} & \frac{\partial y}{\partial x_{22}} & \cdots & \frac{\partial y}{\partial x_{2n}}\\
\cdots & \cdots & \cdots & \cdots \\
\frac{\partial y}{\partial x_{n1}} & \frac{\partial y}{\partial x_{n2}} & \cdots & \frac{\partial y}{\partial x_{nn}}\\
\end{bmatrix}
$$
所以这实际上只是一种记号，对矩阵/向量求导实际上就是对其中的每个元素求导，再按照原有的顺序摆好。

由此举例：$f(\boldsymbol{x},W) = ||W\boldsymbol{x}||^2 = \boldsymbol{x}'W'W\boldsymbol{x} = \sum_{i=1}^n (W\boldsymbol{x})_i^2\xlongequal{\triangle}\sum_{k=1}^n q_k^2 = \boldsymbol{q}'\boldsymbol{q}$。求 $\dfrac{\partial f}{\partial W}$，$\dfrac{\partial f}{\partial \boldsymbol{x}}$。
$$
\boldsymbol{q} = W\boldsymbol{x} = \begin{bmatrix}
W_{11}x_1 + \cdots + W_{1n} x_n\\
W_{21}x_1 + \cdots + W_{2n} x_n\\
\cdots\\
W_{n1}x_1 + \cdots + W_{nn} x_n\\
\end{bmatrix}
$$
由矩阵微商，$\dfrac{\mathrm{d}f}{\mathrm{d}\boldsymbol{q}} = I_n\boldsymbol{q} + I_n'\boldsymbol{q} = 2\boldsymbol{q}$，是个向量。

而要想求 $\dfrac{\partial f}{\partial W}$，即求 $\dfrac{\partial f}{\partial W_{ij}}$
$$
\dfrac{\partial f}{\partial W_{ij}} = \sum_{k=1}^n\dfrac{\partial f}{\partial q_{k}}\dfrac{\partial q_k}{\partial W_{ij}} = \sum_{k=1}^n 2q_k x_j\delta_{k-i} = 2q_ix_j
$$
得到
$$
\dfrac{\partial f}{\partial W} = \begin{bmatrix}
2q_1x_1 & 2q_1x_2 & \cdots & 2q_1x_n\\
2q_2x_1 & 2q_2x_2 & \cdots & 2q_2x_n\\
\cdots & \cdots & \cdots & \cdots \\
2q_nx_1 & 2q_nx_2 & \cdots & 2q_nx_n\\
\end{bmatrix}
$$
同理，要想求 $\dfrac{\partial f}{\partial \boldsymbol{x}}$，即求 $\dfrac{\partial f}{\partial x_i}$
$$
\dfrac{\partial f}{\partial x_i} = \sum_{k=1}^n\dfrac{\partial f}{\partial q_{k}}\dfrac{\partial q_k}{\partial x_{i}} = \sum_{k=1}^n 2q_k W_{ki}
$$
得到 $\dfrac{\partial f}{\partial \boldsymbol{x}} = 2W'\boldsymbol{q}$。

```python
class ComputationalGraph(object):
    def forward(inputs):
        for gate in self.graph.nodes_topologically_sorded():
            gate.forward()
        return loss # The final gate in the graph outputs the loss
    def backward():
        for gate in reversed(self.graph.nodes_topologically_sorded()):
            gate.backward()
        return inputs_gradients
class MultiplyGate(object):
    def forawrd(x, y):
        z = x * y
        self.x = x
        self.y = y
        return z
    def backward(dz):
        dx = self.y * dz
        dy = self.x * dz
        return [dx, dy]
```

## 5 Convolutional Neural Network

### Neural Network

``` python
import numpy as np
from numpy.random import randn

N, D_in, H, D_out = 64, 1000, 100, 10
x, y = randn(N, D_in), randn(N, D_out)
w1, w2 = randn(D_in, H), randn(H, D_out)

for t in range(2000):
    h = 1 / (1 + np.exp(-x.dot(w1)))
    y_pred = h.dot(w2)
    loss = np.square(y_pred - y).sum()
    print(t, loss)
    
    grad_y_pred = 2.0 * (y_pred - y)
    grad_w2 = h.T.dot(grad_y_pred)
    grad_h = grad_y_pred.dot(w2.T)
    grad_w1 = x.T.dot(grad_h * h * (1 - h))
    
    w1 -= 1e-4 * grad_w1
    w2 -= 1e-4 * grad_w2
```

